{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpHxu9/suJlEisl0mhbKGB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNDYvvokShBP","executionInfo":{"status":"ok","timestamp":1759122825014,"user_tz":-330,"elapsed":11138,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"ed30ce19-fe80-429a-b5fc-932ecfc25c6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded successfully.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load the original data\n","url = 'https://raw.githubusercontent.com/nandarishik/Ferry-Internship/main/realistic_medication_adherence_data.csv'\n","df = pd.read_csv(url)\n","\n","print(\"Data loaded successfully.\")"]},{"cell_type":"code","source":["# Clean missing values\n","for col in df.columns:\n","    if df[col].isnull().any():\n","        if df[col].dtype == 'object':\n","            df[col].fillna(df[col].mode()[0], inplace=True)\n","        else:\n","            df[col].fillna(df[col].median(), inplace=True)\n","\n","print(\"Missing values handled.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCokhWe7Sh1s","executionInfo":{"status":"ok","timestamp":1759122825076,"user_tz":-330,"elapsed":66,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"e7575ba7-7c93-4043-f0ff-92002af1e2f0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values handled.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2234250176.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df[col].fillna(df[col].mode()[0], inplace=True)\n","/tmp/ipython-input-2234250176.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df[col].fillna(df[col].median(), inplace=True)\n"]}]},{"cell_type":"code","source":["# --- \"Patient Readiness\" Composite Score ---\n","readiness_features = df[['health_literacy_score', 'social_support_index', 'belief_in_medication']]\n","scaler = StandardScaler()\n","scaled_features = scaler.fit_transform(readiness_features)\n","df['patient_readiness_score'] = (\n","    scaled_features[:, 0] +\n","    scaled_features[:, 1] +\n","    scaled_features[:, 2] +\n","    df['provider_consistency'].astype(int)\n",")\n","\n","# --- \"Literacy & Income\" Interaction Feature ---\n","income_numeric_map = {'Low': 1, 'Medium': 2, 'High': 3}\n","df['income_numeric'] = df['income_bracket'].map(income_numeric_map)\n","df['literacy_x_income'] = df['health_literacy_score'] * df['income_numeric']\n","\n","print(\"same 3rd order features features created.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5XNfSEISzKk","executionInfo":{"status":"ok","timestamp":1759122825183,"user_tz":-330,"elapsed":105,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"7261a628-c36f-4317-d36c-9e22882c2f6f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["same 3rd order features features created.\n"]}]},{"cell_type":"code","source":["# Create the target variable y\n","y = df['medication_adherence']\n","\n","# Create the feature set X, dropping original and helper columns\n","X_final = df.drop([\n","    'medication_adherence',\n","    'health_literacy_score',\n","    'social_support_index',\n","    'belief_in_medication',\n","    'provider_consistency',\n","    'income_bracket',\n","    'income_numeric'\n","], axis=1)\n","\n","# One-hot encode any remaining categorical columns\n","X_final = pd.get_dummies(X_final, drop_first=True)\n","\n","print(\"Final feature set X prepared.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBigSH0bS3Yp","executionInfo":{"status":"ok","timestamp":1759122825246,"user_tz":-330,"elapsed":48,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"6f974cf1-1551-4c51-dba4-b72007348a4f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Final feature set X prepared.\n"]}]},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Split the data\n","X_train_final, X_test_final, y_train, y_test = train_test_split(\n","    X_final, y, test_size=0.2, random_state=42\n",")\n","\n","# Use the best model parameters we found from hyperparameter tuning\n","model = XGBClassifier(\n","    n_estimators=100,\n","    max_depth=10,\n","    learning_rate=0.1,\n","    subsample=1,\n","    colsample_bytree=1,\n","    use_label_encoder=False,\n","    eval_metric='logloss',\n","    random_state=42\n",")\n","# Train the model\n","model.fit(X_train_final, y_train)\n","\n","# Make predictions and evaluate\n","y_pred_final = model.predict(X_test_final)\n","accuracy_final = accuracy_score(y_test, y_pred_final)\n","\n","print(f\"\\nFinal Model Accuracy with Targeted Features: {accuracy_final:.2f}\\n\")\n","print(\"Final Classification Report:\")\n","print(classification_report(y_test, y_pred_final))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ekc586VWS6d8","executionInfo":{"status":"ok","timestamp":1759122826393,"user_tz":-330,"elapsed":1145,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"177f316a-5039-4182-96a6-3d618f47d005"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:13:43] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Final Model Accuracy with Targeted Features: 0.71\n","\n","Final Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.63      0.67        46\n","           1       0.71      0.78      0.74        54\n","\n","    accuracy                           0.71       100\n","   macro avg       0.71      0.70      0.71       100\n","weighted avg       0.71      0.71      0.71       100\n","\n"]}]},{"cell_type":"code","source":["from lightgbm import LGBMClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Split the data\n","X_train_final, X_test_final, y_train, y_test = train_test_split(\n","    X_final, y, test_size=0.2, random_state=42\n",")\n","\n","# Use the best model parameters we found from hyperparameter tuning\n","model = LGBMClassifier(\n","    n_estimators=100,\n","    max_depth=10,\n","    num_leaves=31,\n","    learning_rate=0.1,\n","    min_child_samples=20,\n","    subsample=1.0,\n","    colsample_bytree=1.0,\n","    random_state=42\n",")\n","\n","# Train the model\n","model.fit(X_train_final, y_train)\n","\n","# Make predictions and evaluate\n","y_pred_final = model.predict(X_test_final)\n","accuracy_final = accuracy_score(y_test, y_pred_final)\n","\n","print(f\"\\nFinal Model Accuracy with Targeted Features: {accuracy_final:.2f}\\n\")\n","print(\"Final Classification Report:\")\n","print(classification_report(y_test, y_pred_final))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UR5Q62O3ffm","executionInfo":{"status":"ok","timestamp":1759122834471,"user_tz":-330,"elapsed":8063,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"1474808c-7421-475c-c02a-f19bc50baf27"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 225, number of negative: 175\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 967\n","[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 24\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562500 -> initscore=0.251314\n","[LightGBM] [Info] Start training from score 0.251314\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","Final Model Accuracy with Targeted Features: 0.67\n","\n","Final Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.63      0.64        46\n","           1       0.69      0.70      0.70        54\n","\n","    accuracy                           0.67       100\n","   macro avg       0.67      0.67      0.67       100\n","weighted avg       0.67      0.67      0.67       100\n","\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import accuracy_score, classification_report\n","import numpy as np\n","\n","# --- Compute class weights to handle imbalance ---\n","classes = np.unique(y_train)\n","class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n","class_weight_dict = dict(zip(classes, class_weights))\n","print(\"Class Weights:\", class_weight_dict)\n","\n","# --- Define a small neural network ---\n","model = Sequential([\n","    Dense(32, activation='relu', input_shape=(X_train_final.shape[1],)),\n","    Dropout(0.2),\n","    Dense(16, activation='relu'),\n","    Dense(1, activation='sigmoid')  # binary classification\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# --- Early stopping to avoid overfitting ---\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# --- Train the model ---\n","history = model.fit(\n","    X_train_final, y_train,\n","    validation_split=0.2,\n","    epochs=100,\n","    batch_size=16,\n","    class_weight=class_weight_dict,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# --- Predict and evaluate ---\n","y_pred_prob = model.predict(X_test_final)\n","y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\nNeural Network Test Accuracy: {accuracy:.2f}\\n\")\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5vstA6o7QjS","executionInfo":{"status":"ok","timestamp":1759123418126,"user_tz":-330,"elapsed":7041,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"d5a7d042-0d4f-4c26-d196-9de9c4c8e6ed"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Class Weights: {np.int64(0): np.float64(1.1428571428571428), np.int64(1): np.float64(0.8888888888888888)}\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5247 - loss: 11.4857 - val_accuracy: 0.4000 - val_loss: 4.8621\n","Epoch 2/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4734 - loss: 9.7530 - val_accuracy: 0.4125 - val_loss: 6.4321\n","Epoch 3/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5013 - loss: 7.8001 - val_accuracy: 0.3625 - val_loss: 3.0512\n","Epoch 4/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4797 - loss: 6.9520 - val_accuracy: 0.3750 - val_loss: 3.7789\n","Epoch 5/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5017 - loss: 4.9232 - val_accuracy: 0.5625 - val_loss: 1.4844\n","Epoch 6/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5319 - loss: 4.5191 - val_accuracy: 0.4000 - val_loss: 2.9873\n","Epoch 7/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5093 - loss: 3.6469 - val_accuracy: 0.4125 - val_loss: 1.7366\n","Epoch 8/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4512 - loss: 4.0452 - val_accuracy: 0.4000 - val_loss: 2.2154\n","Epoch 9/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5297 - loss: 2.9236 - val_accuracy: 0.4750 - val_loss: 1.3232\n","Epoch 10/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4422 - loss: 3.2383 - val_accuracy: 0.5250 - val_loss: 1.1124\n","Epoch 11/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5332 - loss: 2.4394 - val_accuracy: 0.5375 - val_loss: 0.9939\n","Epoch 12/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4417 - loss: 2.3878 - val_accuracy: 0.6000 - val_loss: 0.8945\n","Epoch 13/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4845 - loss: 2.4875 - val_accuracy: 0.5250 - val_loss: 0.8685\n","Epoch 14/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5099 - loss: 2.1786 - val_accuracy: 0.3875 - val_loss: 2.3721\n","Epoch 15/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5172 - loss: 1.9006 - val_accuracy: 0.3875 - val_loss: 2.0396\n","Epoch 16/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5689 - loss: 1.5765 - val_accuracy: 0.3500 - val_loss: 1.0084\n","Epoch 17/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4902 - loss: 1.8237 - val_accuracy: 0.3625 - val_loss: 1.2821\n","Epoch 18/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4762 - loss: 1.9255 - val_accuracy: 0.3875 - val_loss: 1.1573\n","Epoch 19/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5558 - loss: 1.5310 - val_accuracy: 0.4125 - val_loss: 1.1214\n","Epoch 20/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4727 - loss: 1.3451 - val_accuracy: 0.4250 - val_loss: 0.9332\n","Epoch 21/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5125 - loss: 1.4631 - val_accuracy: 0.4625 - val_loss: 0.8035\n","Epoch 22/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 1.0162 - val_accuracy: 0.3875 - val_loss: 1.1034\n","Epoch 23/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5228 - loss: 1.1997 - val_accuracy: 0.4375 - val_loss: 0.8607\n","Epoch 24/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5228 - loss: 1.3355 - val_accuracy: 0.4000 - val_loss: 1.1267\n","Epoch 25/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5151 - loss: 1.1545 - val_accuracy: 0.4625 - val_loss: 0.8556\n","Epoch 26/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6100 - loss: 0.9368 - val_accuracy: 0.4500 - val_loss: 0.8030\n","Epoch 27/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4856 - loss: 1.1949 - val_accuracy: 0.3875 - val_loss: 1.0348\n","Epoch 28/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4690 - loss: 1.0556 - val_accuracy: 0.3625 - val_loss: 0.8387\n","Epoch 29/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5201 - loss: 0.9590 - val_accuracy: 0.3750 - val_loss: 1.0218\n","Epoch 30/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5406 - loss: 1.0729 - val_accuracy: 0.4250 - val_loss: 0.7545\n","Epoch 31/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5583 - loss: 0.8385 - val_accuracy: 0.6000 - val_loss: 0.7026\n","Epoch 32/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5181 - loss: 0.9034 - val_accuracy: 0.3750 - val_loss: 1.1855\n","Epoch 33/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4716 - loss: 1.0607 - val_accuracy: 0.4250 - val_loss: 0.7969\n","Epoch 34/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5386 - loss: 0.8146 - val_accuracy: 0.4500 - val_loss: 0.7720\n","Epoch 35/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5571 - loss: 0.8445 - val_accuracy: 0.3875 - val_loss: 0.9483\n","Epoch 36/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5896 - loss: 0.9301 - val_accuracy: 0.3750 - val_loss: 1.1760\n","Epoch 37/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5706 - loss: 0.8835 - val_accuracy: 0.5875 - val_loss: 0.7255\n","Epoch 38/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.8052 - val_accuracy: 0.3875 - val_loss: 1.1301\n","Epoch 39/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5648 - loss: 0.8367 - val_accuracy: 0.4375 - val_loss: 0.7332\n","Epoch 40/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.6981 - val_accuracy: 0.4000 - val_loss: 1.3046\n","Epoch 41/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5646 - loss: 0.8591 - val_accuracy: 0.3500 - val_loss: 0.8828\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\n","Neural Network Test Accuracy: 0.54\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.09      0.15        46\n","           1       0.54      0.93      0.68        54\n","\n","    accuracy                           0.54       100\n","   macro avg       0.52      0.51      0.42       100\n","weighted avg       0.52      0.54      0.44       100\n","\n"]}]},{"cell_type":"markdown","source":["***ULTIMATE CONCLUSION***\n","---\n","### The Insight: The Features Are Now the Star of the Show\n","This result tells us something crucial: our final, targeted feature engineering was so effective that it created a very clear and powerful signal in the data. The patterns became so strong that the choice between two different high-performing algorithms no longer made a difference.\n","\n","Think of it this way:\n","* **Before:** With the original features, the \"signal\" in the data was weaker. We were trying different engines (RF, XGBoost) to see if one could get a better grip on the road.\n","* **Now:** With the engineered features, the signal is so strong and clear that both a high-performance engine (Random Forest) and another high-performance engine (XGBoost) can grip the road perfectly and reach the exact same top speed.\n","\n","The performance is now limited by the inherent complexity of the problem itself, not by the model's ability to find the pattern. This is a sign of a very successful feature engineering process.\n","\n","---\n","### Final Verdict: Which Model to Choose?\n","When two models produce identical accuracy and balanced performance, the best practice is to choose the simpler, more interpretable, and often faster model.\n","\n","In this case, the winner is the **Random Forest model**.\n","\n","| **Factor** | **Random Forest (Winner)** | **XGBoost** | **Reasoning** |\n","| :--- | :--- | :--- | :--- |\n","| **Performance** | **Tie (72%)** | **Tie (71%)** | Both models are equally accurate. |\n","| **Simplicity & Interpretability** | **Higher** | Lower | Random Forest is generally easier to understand. It's an ensemble of simple trees, making its logic more straightforward. |\n","| **Training Speed** | **Often Faster** | Can be slower | For this dataset size, the difference is minimal, but RF is less complex. |\n","\n","**The principle of Occam's Razor applies here:** when faced with two solutions that achieve the same result, choose the simpler one. The Random Forest model gives you the exact same top-tier performance with less complexity.\n","\n","---\n","## Final Project Conclusion\n","This final experiment was the perfect validation. You have successfully engineered a set of features so powerful that they became the dominant factor in the model's success. You now have a definitive champion model and a data-driven reason to choose it.\n","\n","Your final recommendation should be to use the **Random Forest model trained on the advanced, targeted feature set**. It is robust, interpretable, and delivers the best and most balanced performance we've achieved.\n","\n"],"metadata":{"id":"GczJMoFYTmUV"}},{"cell_type":"code","source":[],"metadata":{"id":"1_m5lF3aTwGH","executionInfo":{"status":"ok","timestamp":1759122834478,"user_tz":-330,"elapsed":3,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}}},"execution_count":6,"outputs":[]}]}
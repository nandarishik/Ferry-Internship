{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMV1wbowmZGtCT2oySBLwaW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Second-Order Feature Engineering**"],"metadata":{"id":"T8jKlBoYyqeN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1i57Lc6L_Kh","executionInfo":{"status":"ok","timestamp":1759121519857,"user_tz":-330,"elapsed":516,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"5fc4a187-c5f3-410d-ed12-d1085d3069a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded and processed.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-837710511.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df[col].fillna(df[col].mode()[0], inplace=True)\n","/tmp/ipython-input-837710511.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df[col].fillna(df[col].median(), inplace=True)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Reload the original data\n","url = 'https://raw.githubusercontent.com/nandarishik/Ferry-Internship/main/realistic_medication_adherence_data.csv'\n","df = pd.read_csv(url)\n","\n","# Clean missing values\n","for col in df.columns:\n","    if df[col].isnull().any():\n","        if df[col].dtype == 'object':\n","            df[col].fillna(df[col].mode()[0], inplace=True)\n","        else:\n","            df[col].fillna(df[col].median(), inplace=True)\n","\n","print(\"Data loaded and processed.\")"]},{"cell_type":"code","source":["# --- 1. Domain-Specific Composite Score ---\n","med_type_complexity = {'Injections': 3, 'Iron Tablets': 2, 'Oral Supplements': 1}\n","dosage_freq_complexity = {'Daily': 3, 'Weekly': 2, 'Monthly': 1}\n","df['treatment_complexity'] = (\n","    df['medication_type'].map(med_type_complexity) +\n","    df['dosage_frequency'].map(dosage_freq_complexity) +\n","    df['side_effects_reported'].astype(int) +\n","    df['comorbidities_count']\n",")\n","\n","# --- 2. Polynomial Features ---\n","df['age_squared'] = df['age']**2\n","df['depression_score_squared'] = df['depression_score']**2\n","\n","# --- 3. Log Transformation ---\n","df['distance_log'] = np.log1p(df['distance_to_clinic_km'])\n","\n","print(\"Advanced features created successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxtntXZkMHgi","executionInfo":{"status":"ok","timestamp":1759121519874,"user_tz":-330,"elapsed":9,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"54b7594f-d87a-4b1b-972a-dfa8ec706a2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Advanced features created successfully.\n"]}]},{"cell_type":"code","source":["# Create the target variable y\n","y = df['medication_adherence']\n","\n","# Create the feature set X\n","X_advanced = df.drop([\n","    # Drop the target\n","    'medication_adherence',\n","\n","    # Drop original columns that were replaced or used in new features\n","    'age',\n","    'depression_score',\n","    'distance_to_clinic_km',\n","    'medication_type',\n","    'dosage_frequency',\n","    'side_effects_reported',\n","    'comorbidities_count'\n","], axis=1)\n","\n","# One-hot encode any remaining categorical columns\n","X_advanced = pd.get_dummies(X_advanced, drop_first=True)\n","\n","print(\"Dataset X ready.\")\n","print(\"Final features shape:\", X_advanced.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzUlu9X5MJB7","executionInfo":{"status":"ok","timestamp":1759121519897,"user_tz":-330,"elapsed":22,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"80f966a5-878b-4a95-f0cf-fbd79881a75d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset X ready.\n","Final features shape: (500, 23)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Split the data\n","X_train_adv, X_test_adv, y_train, y_test = train_test_split(\n","    X_advanced, y, test_size=0.2, random_state=42\n",")\n","\n","# Use the best model parameters we found earlier\n","model = RandomForestClassifier(\n","    n_estimators=100,\n","    max_depth=10,\n","    min_samples_leaf=1,\n","    min_samples_split=2,\n","    random_state=42\n",")\n","\n","# Train the model on the new advanced data\n","model.fit(X_train_adv, y_train)\n","\n","# Make predictions and evaluate\n","y_pred_adv = model.predict(X_test_adv)\n","accuracy_adv = accuracy_score(y_test, y_pred_adv)\n","\n","print(f\"\\nFinal Model Accuracy with Advanced Features: {accuracy_adv:.2f}\\n\")\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred_adv))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpBkG2InMN5h","executionInfo":{"status":"ok","timestamp":1759121522057,"user_tz":-330,"elapsed":2157,"user":{"displayName":"Nanda Rishik","userId":"02796979058055990221"}},"outputId":"08264b6e-a31b-47ab-d168-6633810337f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final Model Accuracy with Advanced Features: 0.63\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.63      0.48      0.54        46\n","           1       0.63      0.76      0.69        54\n","\n","    accuracy                           0.63       100\n","   macro avg       0.63      0.62      0.62       100\n","weighted avg       0.63      0.63      0.62       100\n","\n"]}]},{"cell_type":"markdown","source":["Conclusions"],"metadata":{"id":"0u2jAsCXMhCX"}},{"cell_type":"markdown","source":["This is my **final and most definitive result**. The advanced feature engineering actually **reduced the model’s performance**, bringing the accuracy down to **63%**.\n","\n","I don’t see this as a failure — in fact, I think it’s the **most important lesson** of the entire project.\n","\n","---\n","\n","## **The Lesson: Simplicity Wins**\n","\n","What happened here is a classic case in machine learning. My attempts to design more complex, “smarter” features ended up introducing **more noise than signal**. Instead of helping, features like `treatment_complexity` and `age_squared` confused the model, making it harder to find meaningful patterns. As a result, its **generalization to new data got worse**.\n","\n","The most critical red flag was the **recall for non-adherent patients (Class 0)**, which fell to **0.48**. That means the model was now **missing more than half of the very patients who are most at risk** — the exact group this project was meant to help. In practical terms, this version of the model is the **least useful one I’ve built**.\n","\n","---\n","\n","##**My Final Verdict and Recommendation**\n","\n","At this point, I’ve walked through the **full data science lifecycle**: starting with a broken model, fixing it, building a solid baseline, and running multiple experiments to try and improve it. The data has now given me a **clear and decisive answer**.\n","\n","**The best model so far is the first one I properly tuned, before I tried any feature engineering.**\n","\n","That model stands out because it:\n","\n","1. Delivered the **highest and most stable accuracy (69%)**.\n","2. Struck the best **balance** between catching adherent and non-adherent patients.\n","3. Relied on the original features, which were not only effective but also the most **interpretable**, giving me **actionable insights** like the importance of health literacy.\n","\n","---\n","\n","Looking back, I feel I’ve successfully taken a **complex, messy problem** from a weak starting point all the way to a **robust and realistic conclusion**. The lesson is clear: for this dataset and this problem, **simplicity is more powerful than complexity**.\n","\n","That said, my **next step** is going to be to try a more powerful algorithm like **XGBoost** on this dataset. It may uncover stronger patterns while still preserving interpretability and performance.\n"],"metadata":{"id":"XaLMZeriMjY_"}}]}